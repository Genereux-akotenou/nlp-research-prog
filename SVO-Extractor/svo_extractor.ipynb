{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVO-Extractor</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throught this notebook, we are going to find Subject, Verb, Object from text usign spaCy and NLTK library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./favicon.png' alt='image'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install nltk\n",
    "! pip install spacy\n",
    "#! python3 -m spacy download en_core_web_sm\n",
    "#! python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency markers for subjects\n",
    "SUBJECTS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"}\n",
    "\n",
    "# dependency markers for objects\n",
    "OBJECTS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>FUNCTIONS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVOFinder(tok_args):\n",
    "    svo = []\n",
    "    \n",
    "    #let first retreive all verbs\n",
    "    verbs = [tok for tok in tok_args if tok.pos_ == 'VERB' and tok.dep_ != 'aux']\n",
    "    \n",
    "    #then let find the subject of each verb\n",
    "    for verb in verbs:\n",
    "        subjects, verbNegated = SujectFinder(verb)\n",
    "        \n",
    "        #if we found subject then we try to get related object\n",
    "        if(len(subjects) > 0):\n",
    "            v2, objects = ObjectFinder(verb)\n",
    "            \n",
    "            for sub in subjects:\n",
    "                for obj in objects:\n",
    "                    objNegated = isNegated(obj)\n",
    "                    tuple_result = (sub.lower_, '!'+verb.lemma_ if verbNegated or objNegated else verb.lemma_, obj.lower_)\n",
    "                    svo.append(tuple_result)\n",
    "    \n",
    "    return svo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SujectFinder(verb):\n",
    "    verbNegated = isNegated(verb)\n",
    "    subjects = [tok for tok in verb.lefts if tok.dep_ in SUBJECTS and tok.pos_ != 'DET']\n",
    "    \n",
    "    if len(subjects) > 0:\n",
    "        subjects.extend(SubjectsFromConjunctionsFinder(subjects))\n",
    "    else:\n",
    "        foundSubs, verbNegated = findSubs(verb)\n",
    "        subjects.extend(foundSubs)\n",
    "        \n",
    "    return subjects, verbNegated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubjectsFromConjunctionsFinder(subjects):\n",
    "    moreSubjects = []\n",
    "    for subject in subjects:\n",
    "        rights = list(subject.rights)\n",
    "        rightDeps = {tok.lower_ for tok in rights}\n",
    "        if 'and' in rightDeps:\n",
    "            moreSubjects.extend([tok for tok in rights if tok.dep_ in SUBJECTS or tok.pos_ == \"NOUN\"])\n",
    "            if len(moreSubs) > 0:\n",
    "                moreSubjects.extend(getSubsFromConjunctions(moreSubs))\n",
    "                \n",
    "    return moreSubjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSubs(tok):\n",
    "    head = tok.head\n",
    "    while head.pos_ != 'VERB' and head.pos_ != 'NOUN' and head.head != head:\n",
    "        head = head.head\n",
    "    if head.pos_ == 'VERB':\n",
    "        subjects = [tok for tok in head.lefts if tok.dep_ == 'SUB']\n",
    "        if len(subjects) > 0:\n",
    "            verbNegated = isNegated(head)\n",
    "            subjects.extend(SubjectsFromConjunctionsFinder(subjects))\n",
    "            return subjects, verbNegated\n",
    "        elif head.head != head:\n",
    "            return findSubs(head)\n",
    "    elif head.pos_ == 'NOUN':\n",
    "        return [head], isNegated(tok)\n",
    "    return [], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNegated(tok):\n",
    "    negations = {'no', 'not', 'n\\'t', 'never','none'}\n",
    "    for dep in list(tok.lefts) + list(tok.rights):\n",
    "        if dep.lower_ in negations:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjectFinder(verb):\n",
    "    rights = list(verb.rights)\n",
    "    objects = [tok for tok in rights if tok.dep_ in OBJECTS]\n",
    "    objects.extend(objectsFromPrepositionsFinder(rights))\n",
    "    \n",
    "    potentialNewVerb, potentialNewObject = ObjectsFromXCompFinder(rights)\n",
    "    if potentialNewVerb is not None and potentialNewObject is not None and len(potentialNewObject) > 0:\n",
    "        objects.extend(potentialNewObject)\n",
    "        verb = potentialNewVerb\n",
    "    if len(objects) > 0:\n",
    "        objects.extend(objectsFromPrepositionsFinder(objects))\n",
    "    return verb, objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectsFromPrepositionsFinder(deps):\n",
    "    objects = []\n",
    "    for dep in deps:\n",
    "        if dep.pos_ == 'ADP' and dep.dep_ == 'prep':\n",
    "            objects.extend([tok for tok in dep.rights if tok.dep_ in OBJECTS or (tok.pos_ == 'PRON' and tok.lower_ == 'me')])\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjectsFromXCompFinder(deps):\n",
    "    for dep in deps:\n",
    "        if dep.pos_ == 'VERB' and dep.dep_ == 'xcomp':\n",
    "            v = dep\n",
    "            rights = list(v.rights)\n",
    "            objects = [tok for tok in rights if tok.dep_ in OBJECTS]\n",
    "            objects.extend(objectsFromPrepositionsFinder(rights))\n",
    "            if len(objects) > 0:\n",
    "                return verb, objects\n",
    "    return  None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MAIN</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svo_engin(text=\"\"):\n",
    "    tok = NLP(text)\n",
    "    #return text\n",
    "    return SVOFinder(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adam', '!love', 'jack'), ('i', 'love', 'girl')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_engin(\"Adam doesn't love jack or him brother. It seems i love this girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: HAVE TO OPTIMISE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
